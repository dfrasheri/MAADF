{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bY0-J3_BQvq"
      },
      "outputs": [],
      "source": [
        "# BIDDER EVALUATION SYSTEM - Google Colab Version\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Step 1: Generate Sample Bidder Data\n",
        "np.random.seed(42)\n",
        "\n",
        "bidders = [f\"Bidder_{i+1}\" for i in range(15)]\n",
        "data = {\n",
        "    \"Bidder\": bidders,\n",
        "    \"Cost\": np.random.randint(100000, 500000, size=len(bidders)),\n",
        "    \"Experience\": np.random.randint(1, 10, size=len(bidders)),  # in years\n",
        "    \"QualityScore\": np.random.randint(60, 100, size=len(bidders)),  # out of 100\n",
        "    \"DeliveryTime\": np.random.randint(15, 60, size=len(bidders))  # in days\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"=== Raw Bidder Data ===\")\n",
        "print(df)\n",
        "\n",
        "# Step 2: Define Evaluation Weights\n",
        "# Lower cost and delivery time is better. Higher experience and quality is better.\n",
        "weights = {\n",
        "    \"Cost\": 0.4,\n",
        "    \"Experience\": 0.2,\n",
        "    \"QualityScore\": 0.3,\n",
        "    \"DeliveryTime\": 0.1\n",
        "}\n",
        "\n",
        "print(\"\\n=== Evaluation Criteria Weights ===\")\n",
        "print(weights)\n",
        "\n",
        "# Step 3: Normalize Data for Fair Comparison\n",
        "df_normalized = df.copy()\n",
        "\n",
        "# Normalize cost and delivery time by min-max (lower is better ‚Üí inverse)\n",
        "df_normalized[\"Cost\"] = 1 - (df[\"Cost\"] - df[\"Cost\"].min()) / (df[\"Cost\"].max() - df[\"Cost\"].min())\n",
        "df_normalized[\"DeliveryTime\"] = 1 - (df[\"DeliveryTime\"] - df[\"DeliveryTime\"].min()) / (df[\"DeliveryTime\"].max() - df[\"DeliveryTime\"].min())\n",
        "\n",
        "# Normalize experience and quality (higher is better)\n",
        "df_normalized[\"Experience\"] = (df[\"Experience\"] - df[\"Experience\"].min()) / (df[\"Experience\"].max() - df[\"Experience\"].min())\n",
        "df_normalized[\"QualityScore\"] = (df[\"QualityScore\"] - df[\"QualityScore\"].min()) / (df[\"QualityScore\"].max() - df[\"QualityScore\"].min())\n",
        "\n",
        "print(\"\\n=== Normalized Data ===\")\n",
        "print(df_normalized)\n",
        "\n",
        "# Step 4: Weighted Scoring\n",
        "def calculate_score(row, weights):\n",
        "    score = 0\n",
        "    for k in weights:\n",
        "        score += row[k] * weights[k]\n",
        "    return score\n",
        "\n",
        "df_normalized[\"Score\"] = df_normalized.apply(lambda row: calculate_score(row, weights), axis=1)\n",
        "\n",
        "# Step 5: Rank Bidders\n",
        "df_final = df.copy()\n",
        "df_final[\"Score\"] = df_normalized[\"Score\"]\n",
        "df_final[\"Rank\"] = df_final[\"Score\"].rank(ascending=False).astype(int)\n",
        "df_final = df_final.sort_values(by=\"Score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n=== Final Evaluation Results ===\")\n",
        "print(tabulate(df_final, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
        "\n",
        "# Step 6: Visualizations\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.barplot(x='Bidder', y='Score', data=df_final, palette='viridis')\n",
        "plt.title(\"Bidder Evaluation Scores\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(df_normalized.set_index(\"Bidder\")[[\"Cost\", \"Experience\", \"QualityScore\", \"DeliveryTime\"]], annot=True, cmap='coolwarm')\n",
        "plt.title(\"Normalized Bidder Attributes\")\n",
        "plt.show()\n",
        "\n",
        "# Step 7: Show Best Bidder\n",
        "best_bidder = df_final.iloc[0]\n",
        "print(f\"\\nüèÜ Best Bidder: {best_bidder['Bidder']} with Score: {best_bidder['Score']:.3f}\")\n",
        "\n",
        "# Step 8: Export to Excel (if desired)\n",
        "df_final.to_csv(\"bidder_evaluation_results.csv\", index=False)\n",
        "print(\"\\n‚úÖ Evaluation complete. Results saved to 'bidder_evaluation_results.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BIDDER EVALUATION SYSTEM - Google Colab Version\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Step 1: Generate Sample Bidder Data\n",
        "np.random.seed(42)\n",
        "\n",
        "bidders = [f\"Bidder_{i+1}\" for i in range(15)]\n",
        "data = {\n",
        "    \"Bidder\": bidders,\n",
        "    \"Cost\": np.random.randint(100000, 500000, size=len(bidders)),\n",
        "    \"Experience\": np.random.randint(1, 10, size=len(bidders)),  # in years\n",
        "    \"QualityScore\": np.random.randint(60, 100, size=len(bidders)),  # out of 100\n",
        "    \"DeliveryTime\": np.random.randint(15, 60, size=len(bidders))  # in days\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"=== Raw Bidder Data ===\")\n",
        "print(df)\n",
        "\n",
        "# Step 2: Define Evaluation Weights\n",
        "# Lower cost and delivery time is better. Higher experience and quality is better.\n",
        "weights = {\n",
        "    \"Cost\": 0.4,\n",
        "    \"Experience\": 0.2,\n",
        "    \"QualityScore\": 0.3,\n",
        "    \"DeliveryTime\": 0.1\n",
        "}\n",
        "\n",
        "print(\"\\n=== Evaluation Criteria Weights ===\")\n",
        "print(weights)\n",
        "\n",
        "# Step 3: Normalize Data for Fair Comparison\n",
        "df_normalized = df.copy()\n",
        "\n",
        "# Normalize cost and delivery time by min-max (lower is better ‚Üí inverse)\n",
        "df_normalized[\"Cost\"] = 1 - (df[\"Cost\"] - df[\"Cost\"].min()) / (df[\"Cost\"].max() - df[\"Cost\"].min())\n",
        "df_normalized[\"DeliveryTime\"] = 1 - (df[\"DeliveryTime\"] - df[\"DeliveryTime\"].min()) / (df[\"DeliveryTime\"].max() - df[\"DeliveryTime\"].min())\n",
        "\n",
        "# Normalize experience and quality (higher is better)\n",
        "df_normalized[\"Experience\"] = (df[\"Experience\"] - df[\"Experience\"].min()) / (df[\"Experience\"].max() - df[\"Experience\"].min())\n",
        "df_normalized[\"QualityScore\"] = (df[\"QualityScore\"] - df[\"QualityScore\"].min()) / (df[\"QualityScore\"].max() - df[\"QualityScore\"].min())\n",
        "\n",
        "print(\"\\n=== Normalized Data ===\")\n",
        "print(df_normalized)\n",
        "\n",
        "# Step 4: Weighted Scoring\n",
        "def calculate_score(row, weights):\n",
        "    score = 0\n",
        "    for k in weights:\n",
        "        score += row[k] * weights[k]\n",
        "    return score\n",
        "\n",
        "df_normalized[\"Score\"] = df_normalized.apply(lambda row: calculate_score(row, weights), axis=1)\n",
        "\n",
        "# Step 5: Rank Bidders\n",
        "df_final = df.copy()\n",
        "df_final[\"Score\"] = df_normalized[\"Score\"]\n",
        "df_final[\"Rank\"] = df_final[\"Score\"].rank(ascending=False).astype(int)\n",
        "df_final = df_final.sort_values(by=\"Score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n=== Final Evaluation Results ===\")\n",
        "print(tabulate(df_final, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
        "\n",
        "# Step 6: Visualizations\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.barplot(x='Bidder', y='Score', data=df_final, palette='viridis')\n",
        "plt.title(\"Bidder Evaluation Scores\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(df_normalized.set_index(\"Bidder\")[[\"Cost\", \"Experience\", \"QualityScore\", \"DeliveryTime\"]], annot=True, cmap='coolwarm')\n",
        "plt.title(\"Normalized Bidder Attributes\")\n",
        "plt.show()\n",
        "\n",
        "# Step 7: Show Best Bidder\n",
        "best_bidder = df_final.iloc[0]\n",
        "print(f\"\\nüèÜ Best Bidder: {best_bidder['Bidder']} with Score: {best_bidder['Score']:.3f}\")\n",
        "\n",
        "# Step 8: Export to Excel (if desired)\n",
        "df_final.to_csv(\"bidder_evaluation_results.csv\", index=False)\n",
        "print(\"\\n‚úÖ Evaluation complete. Results saved to 'bidder_evaluation_results.csv'\")\n"
      ],
      "metadata": {
        "id": "7MwVyARlxW66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BIDDER EVALUATION SYSTEM - Google Colab Version\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Step 1: Generate Sample Bidder Data\n",
        "np.random.seed(42)\n",
        "\n",
        "bidders = [f\"Bidder_{i+1}\" for i in range(15)]\n",
        "data = {\n",
        "    \"Bidder\": bidders,\n",
        "    \"Cost\": np.random.randint(100000, 500000, size=len(bidders)),\n",
        "    \"Experience\": np.random.randint(1, 10, size=len(bidders)),  # in years\n",
        "    \"QualityScore\": np.random.randint(60, 100, size=len(bidders)),  # out of 100\n",
        "    \"DeliveryTime\": np.random.randint(15, 60, size=len(bidders))  # in days\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"=== Raw Bidder Data ===\")\n",
        "print(df)\n",
        "\n",
        "# Step 2: Define Evaluation Weights\n",
        "# Lower cost and delivery time is better. Higher experience and quality is better.\n",
        "weights = {\n",
        "    \"Cost\": 0.4,\n",
        "    \"Experience\": 0.2,\n",
        "    \"QualityScore\": 0.3,\n",
        "    \"DeliveryTime\": 0.1\n",
        "}\n",
        "\n",
        "print(\"\\n=== Evaluation Criteria Weights ===\")\n",
        "print(weights)\n",
        "\n",
        "# Step 3: Normalize Data for Fair Comparison\n",
        "df_normalized = df.copy()\n",
        "\n",
        "# Normalize cost and delivery time by min-max (lower is better ‚Üí inverse)\n",
        "df_normalized[\"Cost\"] = 1 - (df[\"Cost\"] - df[\"Cost\"].min()) / (df[\"Cost\"].max() - df[\"Cost\"].min())\n",
        "df_normalized[\"DeliveryTime\"] = 1 - (df[\"DeliveryTime\"] - df[\"DeliveryTime\"].min()) / (df[\"DeliveryTime\"].max() - df[\"DeliveryTime\"].min())\n",
        "\n",
        "# Normalize experience and quality (higher is better)\n",
        "df_normalized[\"Experience\"] = (df[\"Experience\"] - df[\"Experience\"].min()) / (df[\"Experience\"].max() - df[\"Experience\"].min())\n",
        "df_normalized[\"QualityScore\"] = (df[\"QualityScore\"] - df[\"QualityScore\"].min()) / (df[\"QualityScore\"].max() - df[\"QualityScore\"].min())\n",
        "\n",
        "print(\"\\n=== Normalized Data ===\")\n",
        "print(df_normalized)\n",
        "\n",
        "# Step 4: Weighted Scoring\n",
        "def calculate_score(row, weights):\n",
        "    score = 0\n",
        "    for k in weights:\n",
        "        score += row[k] * weights[k]\n",
        "    return score\n",
        "\n",
        "df_normalized[\"Score\"] = df_normalized.apply(lambda row: calculate_score(row, weights), axis=1)\n",
        "\n",
        "# Step 5: Rank Bidders\n",
        "df_final = df.copy()\n",
        "df_final[\"Score\"] = df_normalized[\"Score\"]\n",
        "df_final[\"Rank\"] = df_final[\"Score\"].rank(ascending=False).astype(int)\n",
        "df_final = df_final.sort_values(by=\"Score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n=== Final Evaluation Results ===\")\n",
        "print(tabulate(df_final, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
        "\n",
        "# Step 6: Visualizations\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.barplot(x='Bidder', y='Score', data=df_final, palette='viridis')\n",
        "plt.title(\"Bidder Evaluation Scores\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(df_normalized.set_index(\"Bidder\")[[\"Cost\", \"Experience\", \"QualityScore\", \"DeliveryTime\"]], annot=True, cmap='coolwarm')\n",
        "plt.title(\"Normalized Bidder Attributes\")\n",
        "plt.show()\n",
        "\n",
        "# Step 7: Show Best Bidder\n",
        "best_bidder = df_final.iloc[0]\n",
        "print(f\"\\nüèÜ Best Bidder: {best_bidder['Bidder']} with Score: {best_bidder['Score']:.3f}\")\n",
        "\n",
        "# Step 8: Export to Excel (if desired)\n",
        "df_final.to_csv(\"bidder_evaluation_results.csv\", index=False)\n",
        "print(\"\\n‚úÖ Evaluation complete. Results saved to 'bidder_evaluation_results.csv'\")\n"
      ],
      "metadata": {
        "id": "-YbOGQJ7xXqV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}